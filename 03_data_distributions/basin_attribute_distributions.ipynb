{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions of CAMELS attributes\n",
    "Let's explore the distributions of chatchment attributes throughout the U.S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in processed data from file\n",
    "Lesson 01 contains a pipeline from the data source through a slight cleaning process. Then a CSV with the cleaned data will be saved in the data directory. Open that file as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = \"../data/camels/camels_attributes_cleaned_28-05-2023_0833_jf_DO_NOT_COPY.csv\"\n",
    "if os.path.exists(data_file_path):\n",
    "    with open(data_file_path, \"r\") as f:\n",
    "        df = pd.read_csv(f, index_col=\"gauge_id\")\n",
    "else:\n",
    "    print(\"Data file path does not exist. Create the file with lesson 01, then add the path\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore one variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute=\"p_mean\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the distributions\n",
    "There are a lot of interesting distributions in the data. Note that some data are more clearly bounded than others. Some data are more normal. Some are more heavy tailed. Some skewed. Etcetera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram_of_data(df, attribute):\n",
    "    fig, axs = plt.subplots(figsize=(3,3))\n",
    "    axs.hist(df[attribute], bins=50)\n",
    "    axs.set_xlabel(attribute)\n",
    "    axs.set_ylabel(\"Frequency\")    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_of_data(df, attribute)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a hypothesis that the data are normal\n",
    "We'll never have access to all the data. So let's choose a subset of data to sample, then explore both the sample and the full population. Also, we need to set some threshold value to accept our hypothesis, before we begin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_samples = 150\n",
    "beta_value = 0.15 # Value which the KS test has to be under to accept normality of the distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample a target variable with some defined number of random catchments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_and_sample_data(df, K_samples, attribute):\n",
    "    sample_catchments = np.random.choice(df.index.values, K_samples)\n",
    "    d = df.loc[:, attribute]\n",
    "    d_sample = df.loc[sample_catchments, attribute]\n",
    "    return d, d_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, d_sample = get_data_and_sample_data(df, K_samples, attribute)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the statistics values for the sample and full population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics_from_data(d, d_sample):\n",
    "    d_stats = [np.average(d), np.std(d), skew(d), kurtosis(d), np.var(d)]\n",
    "    d_sample_stats = [np.average(d_sample), np.std(d_sample), skew(d_sample), kurtosis(d_sample), np.var(d_sample)]\n",
    "    return d_stats, d_sample_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_stats, d_sample_stats = get_statistics_from_data(d, d_sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the mean and confidence intervals of the sample\n",
    "Comparing to the full population mean, which should be inside the confidence interval, depending on the sample size and confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample_mean_and_confidence_intervals(d, d_sample, confidence):\n",
    "    n = len(d_sample)\n",
    "    se = stats.sem(d_sample)\n",
    "    m = np.mean(d_sample)\n",
    "    h = se * stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    print(f'Lower 90% CI {m-h:.2f}')\n",
    "    print(f'Sample mean {m:.2f}')\n",
    "    print(f'Upper 90% CI {m+h:.2f}')\n",
    "    print(f'True mean {np.mean(d):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sample_mean_and_confidence_intervals(d, d_sample, confidence = 0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want some evenly spaced data spanning some sigma value to use in plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_values(d_stats, d_sample_stats, sigma=4):\n",
    "    x = np.linspace(d_stats[0] - sigma*d_stats[1], \n",
    "                    d_stats[0] + sigma*d_stats[1], 10000)\n",
    "    x_sample = np.linspace(d_sample_stats[0] - sigma*d_sample_stats[1], \n",
    "                           d_sample_stats[0] + sigma*d_sample_stats[1], 10000)\n",
    "    return x, x_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_sample = get_x_values(d_stats, d_sample_stats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some synthetic normal data with the states we've calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_values(x, x_sample, d_stats, d_sample_stats):\n",
    "    y = stats.norm.pdf(x, d_stats[0], d_stats[1])\n",
    "    y_sample = stats.norm.pdf(x_sample, d_sample_stats[0], d_sample_stats[1])\n",
    "    return y, y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y_sample = get_y_values(x, x_sample, d_stats, d_sample_stats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the distributions from the population and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_and_population_distributions(x, x_sample, y, y_sample, attribute):\n",
    "    fig, axs = plt.subplots(figsize=(3,3))\n",
    "    axs.plot(x, y, c='blue', label=\"All catchments\")\n",
    "    axs.plot(x_sample, y_sample, c='green', label=\"sample\")\n",
    "    axs.set_ylabel(\"Probability\")\n",
    "    axs.set_xlabel(attribute)\n",
    "    axs.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample_and_population_distributions(x, x_sample, y, y_sample, attribute)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for normality with a Kalmogorov-Smirnov test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_the_data_normal(data, beta_value):\n",
    "    d_n = (data - np.mean(data)) / np.std(data)\n",
    "    kstest_result = stats.kstest(d_n, 'norm')\n",
    "    if kstest_result[0] < beta_value:\n",
    "        print(\"The data are normal\")\n",
    "    else:\n",
    "        print(\"The data are NOT normal\")\n",
    "    print(kstest_result)\n",
    "    return(kstest_result[0], kstest_result[1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now let's check our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_stat, p_value = are_the_data_normal(d_sample, beta_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the cumulative probability distribution of the sample, population and sythetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_distributions_population_sample_and_synthetic(d, \n",
    "                                                                  d_stats, \n",
    "                                                                  d_sample, \n",
    "                                                                  d_sample_stats, \n",
    "                                                                  attribute):\n",
    "    v01, b01 = np.histogram(np.random.normal(d_stats[0], d_stats[1],100000), bins=10000)\n",
    "    v02, b02 = np.histogram(np.random.normal(d_sample_stats[0], d_sample_stats[1],100000), bins=10000)\n",
    "    v1, b1 = np.histogram(d, bins=20)\n",
    "    v2, b2 = np.histogram(d_sample, bins=20)\n",
    "    v01 = v01/np.max(v01)\n",
    "    v02 = v02/np.max(v02)\n",
    "    v1 = v1/np.max(v1)\n",
    "    v2 = v2/np.max(v2)\n",
    "    c01 = np.cumsum(v01)\n",
    "    c02 = np.cumsum(v02)\n",
    "    c1 = np.cumsum(v1)\n",
    "    c2 = np.cumsum(v2)\n",
    "\n",
    "    fig, axs = plt.subplots(figsize=(3,4))\n",
    "    axs.plot(b01[:-1], c01/np.max(c01), c='k', label=\"Synthetic population data\")\n",
    "    axs.plot(b02[:-1], c02/np.max(c02), \"--\", c='k', label=\"Synthetic sample data\")\n",
    "    axs.plot(b1[:-1], c1/c1[-1], c='blue', label=\"All catchments\")\n",
    "    axs.plot(b2[:-1], c2/c2[-1], c='green', label=\"Sampled catchments\")\n",
    "    axs.grid(color='grey', linestyle='-', linewidth=0.1)\n",
    "    axs.set_ylabel(\"Cumulative probability \\n (exceedence)\")\n",
    "    axs.set_xlabel(attribute)\n",
    "    axs.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cumulative_distributions_population_sample_and_synthetic(d, d_stats, d_sample, d_sample_stats, attribute)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a big function to do all the above\n",
    "With this single function, it will be easier to loop through all our basin attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_attribute_distribution(df, attribute, K_samples, confidence):\n",
    "    \n",
    "    print(\"\\n ---------------------------------\")\n",
    "    print(f\"Exploring distribution of {attribute}\")\n",
    "    \n",
    "    plot_histogram_of_data(df, attribute)\n",
    "    \n",
    "    d, d_sample = get_data_and_sample_data(df, K_samples, attribute)\n",
    "    \n",
    "    d_stats, d_sample_stats = get_statistics_from_data(d, d_sample)\n",
    "    \n",
    "    print_sample_mean_and_confidence_intervals(d, d_sample, confidence=confidence)\n",
    "    \n",
    "    x, x_sample = get_x_values(d_stats, d_sample_stats)\n",
    "    \n",
    "    y, y_sample = get_y_values(x, x_sample, d_stats, d_sample_stats)\n",
    "    \n",
    "    plot_sample_and_population_distributions(x, x_sample, y, y_sample, attribute)\n",
    "    \n",
    "    ks_stat, p_value = are_the_data_normal(d_sample, beta_value)\n",
    "\n",
    "    plot_cumulative_distributions_population_sample_and_synthetic(d, d_stats, d_sample, d_sample_stats, attribute)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop through all the attributes to inspect all the distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, attribute in enumerate(df.columns.values):\n",
    "    explore_attribute_distribution(df, attribute, 60, confidence = 0.9)\n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check some fake data that we know are normal\n",
    "Notice that with a relatively small sample (less than 1000), it is actually kind of hard to get a low KS test score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normal = stats.norm.rvs(size=50,loc=0,scale=1)\n",
    "ks_stat, p_value = are_the_data_normal(data_normal, beta_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about join probability distributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_join_probability(df,attribute1,attribute2):\n",
    "    \n",
    "    x = df[attribute1]\n",
    "    y = df[attribute2]\n",
    "    H, xedges, yedges = np.histogram2d(x, y, bins=(50, 50), normed=True)\n",
    "    areas = np.matmul(np.array([np.diff(xedges)]).T, np.array([np.diff(yedges)]))\n",
    "    # setting normed=True in histogram2d doesn't seem to do what I need\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    im = plt.imshow(H*areas, interpolation='nearest')\n",
    "    plt.colorbar(im)\n",
    "    plt.xlabel(attribute1)\n",
    "    plt.ylabel(attribute2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_join_probability(df,\"p_mean\",\"p_seasonality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
